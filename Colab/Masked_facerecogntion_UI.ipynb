{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alby0n/Masked-Face-Recognition/blob/main/Colab/Masked_facerecogntion_UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run all the cells**\n",
        "`Guidelines:`\n",
        "1.   \n",
        "Last cell is the **User Interface**\n",
        "2.   All the cells are given suitable title for ease of navigation\n",
        "3. ***Ctrl + F9*** to run all cells\n",
        "\n"
      ],
      "metadata": {
        "id": "GTPfiP7VRIvr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmlZnRPCVOXN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive #To connect your personal gdrive to the notebook\n",
        "\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/G-Drive \n",
        "#Change Directory (cd) ; is to assign the drive to our G-Drive folder contents"
      ],
      "metadata": {
        "id": "asYztmm8yF04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai1GDLh5C-KT"
      },
      "outputs": [],
      "source": [
        "!pwd # Print Working Directory (pwd) ; is to check whether we assigned it correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZ0cXQ2833no"
      },
      "outputs": [],
      "source": [
        "#Importing all the necessary libary to run our Face recognition tool\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import PIL\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from tensorflow.keras.models import model_from_json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Detection Model**"
      ],
      "metadata": {
        "id": "CN-A3BX2VQ5y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR4ZKZ9a4wqo"
      },
      "outputs": [],
      "source": [
        "def most_common(List):\n",
        "    return(mode(List))\n",
        "\n",
        "def limitcnt(list5):\n",
        "  x=most_common(list5)\n",
        "  cnt = list5.count(x)\n",
        "  if cnt==8 and gflag==False:\n",
        "    flag=True\n",
        "    gflag=True\n",
        "def finalm(vid,zipfile): \n",
        "  \n",
        "  directory=\"/content/gdrive/MyDrive/G-Drive/Temp_Folder\" #Contains the zipfile dataset\n",
        "  \n",
        "  for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".jpeg\"):\n",
        "        imz=os.path.join(directory, filename)\n",
        "        gi=img_to_encoding(imz,FRmodel)\n",
        "        database[filename] = gi #adding files to database for recognition\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "  \n",
        "  \n",
        "  if os.path.exists('images'):\n",
        "    shutil.rmtree('/content/gdrive/MyDrive/G-Drive/images') #Deleting existing directory to remove garbage files\n",
        "  cam = cv2.VideoCapture(vid) # video file input\n",
        "  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')  \n",
        "  try:\n",
        "      if not os.path.exists('images'):#Creating images folder to store video frames\n",
        "          os.makedirs('images')\n",
        "          print(\"Created\")\n",
        "  except OSError:\n",
        "      print('Error: Creating directory of images')\n",
        "  currentframe = 0\n",
        "  while (True):\n",
        "      ret, frame = cam.read()\n",
        "      if ret:\n",
        "          name = './images/frame' + str(currentframe) + '.jpg'\n",
        "          print('Creating...' + name)\n",
        "          cv2.imwrite(name, frame)\n",
        "          currentframe += 1\n",
        "      else:\n",
        "          break\n",
        "  cam.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "  base_dir = os.path.dirname('!pwd')#setting up the base dir G-Drive to access files\n",
        "  prototxt_path = os.path.join(base_dir + 'model_data/deploy.prototxt') #The .prototxt file(s) which define the model architecture (i.e., the layers themselves)\n",
        "  caffemodel_path = os.path.join(base_dir + 'model_data/weights.caffemodel') #The .caffemodel file which contains the weights for the actual layer\n",
        "\n",
        "  # Read the model\n",
        "  model = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
        "\n",
        "\n",
        "  \n",
        "  # Create directory 'faces' if it does not exist\n",
        "  if not os.path.exists('faces'):\n",
        "      print(\"New directory created\")\n",
        "      os.makedirs('faces')\n",
        "\n",
        "  # Loop through all images and strip out faces\n",
        "  count = 0\n",
        "  Flg=False\n",
        "  list5=[]\n",
        "  flag=False\n",
        "  gflag=False\n",
        "  for file in os.listdir(base_dir + 'images'):\n",
        "      file_name, file_extension = os.path.splitext(file)\n",
        "      if (file_extension in ['.png','.jpg']):\n",
        "          \n",
        "          image = cv2.imread(base_dir + 'images/' + file)\n",
        "\n",
        "          (h, w) = image.shape[:2]\n",
        "          blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "\n",
        "          model.setInput(blob)\n",
        "          detections = model.forward()\n",
        "          try:\n",
        "          # Identify each face\n",
        "            for i in range(0, detections.shape[2]):\n",
        "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "                confidence = detections[0, 0, i, 2]\n",
        "\n",
        "              # If confidence > 0.15, save it as a separate file . It is set to 0.15 is to detect faces with masks but the best practice is to use 0.5\n",
        "                if (confidence > 0.15):\n",
        "                    count += 1\n",
        "                    frame = image[startY:endY, startX:endX]\n",
        "                    cv2.imwrite(base_dir + 'faces/'   + \"gen.jpg\", frame)#Detected face\n",
        "                  \n",
        "                    nope,id=who_is_it(base_dir + 'faces/'   + \"gen.jpg\", database, FRmodel)#Passing detected faces for recognition\n",
        "                    \n",
        "\n",
        "                    if(float(nope)<1.2): #After the confidence (the distance) is good, print the person recognised\n",
        "                      realMen=\"/content/gdrive/MyDrive/G-Drive/Temp Folder/\"+id\n",
        "                      realMen=cv2.imread(realMen)\n",
        "                      Flg=True\n",
        "                      return image,frame,realMen,id\n",
        "                      \n",
        "\n",
        "                      \n",
        "                 \n",
        "\n",
        "                      \n",
        "          except:\n",
        "            pass  \n",
        "  if Flg==False:\n",
        "    ss=\"None found in the database\"#When not found in the database\n",
        "    fakeim=cv2.imread(\"/content/gdrive/MyDrive/G-Drive/1200px-No_Cross.svg.png\")#Can customise the output NOT FOUND image by changing path\n",
        "    return fakeim,fakeim,fakeim,ss\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recognition Model**"
      ],
      "metadata": {
        "id": "HY40nXmPVDmy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mut9gytnQZmw"
      },
      "outputs": [],
      "source": [
        "json_file = open('/content/gdrive/MyDrive/G-Drive/model_data/model.json', 'r') \n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "model.load_weights('/content/gdrive/MyDrive/G-Drive/model_data/model.h5')\n",
        "FRmodel = model\n",
        "def img_to_encoding(image_path, model):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(160, 160))\n",
        "    \n",
        "    img = np.around(np.array(img) / 255.0, decimals=12)\n",
        "    x_train = np.expand_dims(img, axis=0)\n",
        "    embedding = model.predict_on_batch(x_train)\n",
        "    return embedding / np.linalg.norm(embedding, ord=2)\n",
        "\n",
        "database = {}\n",
        "\n",
        "\n",
        "\n",
        "def who_is_it(image_path, database, model):\n",
        "\n",
        "    encoding = img_to_encoding(image_path,model)\n",
        "\n",
        "    min_dist = 100\n",
        "\n",
        "    for (name, db_enc) in database.items():\n",
        "        \n",
        "        # Compute L2 distance between the target \"encoding\" and the current db_enc from the database. (≈ 1 line)\n",
        "        dist = np.linalg.norm(encoding - db_enc)\n",
        "\n",
        "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines)\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            identity = name\n",
        "    \n",
        "    \n",
        "    if min_dist > 1.2:\n",
        "        #print(\"Not in the database.\")\n",
        "        pass\n",
        "    else:\n",
        "      pass\n",
        "        #print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
        "        #print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
        "        \n",
        "    return min_dist, identity\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# USER INTERFACE\n",
        "Built using Gradio Package (https://gradio.app/)"
      ],
      "metadata": {
        "id": "_opd1fK1m2y3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtE-RbnGCa8w"
      },
      "outputs": [],
      "source": [
        "#Debuging to be done via the output cell of gradio , this is the driver function of the programme\n",
        "#This is a gradio setup ; Gradio is the fastest way to demo your machine learning model with a friendly web interface so that anyone can use it, anywhere!\n",
        "import zipfile\n",
        "!pip install --quiet gradio\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "def driverfunc(x,zipf,vid,y):\n",
        "  if os.path.exists('Temp_Folder'):\n",
        "    shutil.rmtree('/content/gdrive/MyDrive/G-Drive/Temp_Folder') #Delete existing folder to remove garbage value\n",
        "\n",
        "  if not os.path.exists('Temp_Folder'):\n",
        "          os.makedirs('Temp_Folder')\n",
        "\n",
        "  directory=\"/content/gdrive/MyDrive/G-Drive/Temp_Folder\" #Folder to store the unzip dataset files\n",
        "  tmp=zipf.name\n",
        "  with zipfile.ZipFile(tmp, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory)\n",
        "  resultimg,resultframe,resultmen,resultid=finalm(vid,zipf.name)\n",
        "  return [resultimg,resultframe,resultmen,resultid,\"Program Terminated\"]\n",
        "    \n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=driverfunc,\n",
        "    inputs=[\n",
        "            gr.inputs.Textbox(lines=2,default=\"Upload The Zip Folder Containing the Images of People To Recognise Here\", label=\" \"),\n",
        "            gr.inputs.File(label=\"Zip Folder\"),\n",
        "            gr.inputs.Video(label=\"Upload the CCTV footage in here\"),\n",
        "            gr.inputs.Textbox(lines=2,default=\"Click Submit After Uploading the Files\", label=\" \")\n",
        "            \n",
        "            ],\n",
        "    outputs=[gr.outputs.Image(label=\"CCTV frame in which the person was detected\"),\n",
        "             gr.outputs.Image(label=\"Detected face of Person\"),\n",
        "             gr.outputs.Image(label=\"Photograph stored in Database\"),\n",
        "             \n",
        "             \n",
        "             gr.outputs.Textbox(type=\"number\"),\n",
        "             gr.outputs.Textbox(label=\"Message:\")],\n",
        "    title=\"FACE RECOGNITION SYSTEM\",\n",
        "    theme=\"darkhuggingface\",\n",
        "    #allow_screenshot=False,\n",
        "    allow_flagging=False,\n",
        "    #live=True\n",
        "     )\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authors\n",
        "\n",
        "- [![portfolio](https://img.shields.io/badge/Aby_Stalin-0AF?style=for-the-badge&logoColor=White)](https://github.com/Alby0n)\n",
        "- [![portfolio](https://img.shields.io/badge/Akhbar_Sha-D62?style=for-the-badge&logoColor=white)](https://github.com/AkhbarSha)\n",
        "- [![portfolio](https://img.shields.io/badge/Shrish_Nandakumar-E23?style=for-the-badge&logoColor=black)](https://github.com/shrishn)\n",
        "- [![portfolio](https://img.shields.io/badge/Akshit_Sudheer_Kumar-000?style=for-the-badge&logoColor=red)](https://github.com/4k5h1t)\n",
        "\n",
        "Click on the names to find us on Github !!!"
      ],
      "metadata": {
        "id": "6pYZdZMAfbMM"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Masked facerecogntion UI.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}